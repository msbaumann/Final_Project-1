{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making my import quotas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'merged.dat' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3da1fd59c632>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loading my data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'merged.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\mim\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mim\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mim\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mim\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mim\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3229)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6042)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'merged.dat' does not exist"
     ]
    }
   ],
   "source": [
    "#loading my data\n",
    "data = pd.read_csv('merged.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before loading the dataset into python, you have to change the filenames by getting rid of the './' at \n",
    "# the beginning of each row. You must do this orelse pandas cannot read the dataset. \n",
    "# We did this in our regular expressions assignment. But now you have to save the changes that you made \n",
    "# through regular expression, to a new file. \n",
    "\n",
    "# There is a command called 'sed' within regular expression, which finds and replaces patterns in files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'merged.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f292a5ade9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#First, open data that needs to be changed via regular expression. This also creates a variable containing the data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'merged.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#read() to \"read\" the strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'merged.dat'"
     ]
    }
   ],
   "source": [
    "#First, open data that needs to be changed via regular expression. This also creates a variable containing the data: \n",
    "\n",
    "lines = open('merged.dat', 'r').read().split('\\n')\n",
    "\n",
    "#read() to \"read\" the strings\n",
    "#split('\\n') to add the newline character to the end of each line to have each line of text be stored as a \n",
    "#separate item in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function, which will delete the './' at the beginning of each row. \n",
    "\n",
    "def get_start(record):\n",
    "    '''Return each row without the ./ at the beginning of the row'''\n",
    "\n",
    "    #re.search() for ./\n",
    "    match = re.search('./([a-z]{4}/[^/]*/[^/]*$)', record)\n",
    "    #The ^ and $ match the beginning and end of a line respectively. \n",
    "    #The * matches zero or more items\n",
    "    \n",
    "    #if re.search() returned a match from the above pattern\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    #If re.search() returns no match \n",
    "    return None \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-bb9a379b926c>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-bb9a379b926c>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    sed \"s/./[a-z]{4}/[^/]*/[^/]*$/[a-z]{4}/[^/]*/[^/]*$/\" merged.dat changed_merged.dat\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#This newly formatted data needs to be saved to a new file. This can be done, by using the sed function. \n",
    "\n",
    "#This is the format of the sed function: sed \"s/<expression>/<substitution>/\" <old file> <new file>\n",
    "#So:\n",
    "\n",
    "sed \"s/./[a-z]{4}/[^/]*/[^/]*$/[a-z]{4}/[^/]*/[^/]*$/\" merged.dat changed_merged.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I dont know why it is giving me a SyntaxError maybe we can discuss this with Tiffany. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that you have a new file with the correct beginnings in each row, it can be succesfully loaded into python, \n",
    "# using whatever library is most appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this data appears to be the \"./\" at the start of each line. The re.sub method should be able to find and replace them with a blank space however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#isolating bits of data\n",
    "new_data = re.search('_(4DayOld)_(4psi)_(CO2_a|b).([1-9]*)', './data/20141118_131037/N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4DayOld\n",
      "4psi\n",
      "CO2_a\n"
     ]
    }
   ],
   "source": [
    "print (new_data.group(1))\n",
    "print (new_data.group(2))\n",
    "print (new_data.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8fbe1e2d07e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "#thought about making a function but didn't\n",
    "def fix_data(data):\n",
    "    '''A function to take the data out of a file format with one column '''\n",
    "    m = re.search('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#another dead end\n",
    "for line in data:\n",
    "    re.sub('./',line,' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9\n",
       "0  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...                        \n",
       "1  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...                        \n",
       "2  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...                        \n",
       "3  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...                        \n",
       "4  ./data/20141118_131037/N2_4DayOld_4psi_CO2_a.0...                        "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gave up on this one too\n",
    "for line in data:\n",
    "    new_data = re.sub('./',' \\n',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stackoverflow gave me this outfile idea\n",
    "outfile = open('test.txt','a')\n",
    "for line in data:\n",
    "#find ./ and replace it with ' '\n",
    "    outfile.write(re.sub(',/','  ',line))\n",
    "    \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9\n"
     ]
    }
   ],
   "source": [
    "#peeking at the file\n",
    "with open(\"test.txt\") as text_file:\n",
    "    contents = text_file.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9 dat 20141118_13103 N2_4DayOld_4psi_CO2_a.00001.dat:15.028 0.00 1 234.9]\n",
       "Index: []"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening it with Pandas\n",
    "pd.read_csv('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
